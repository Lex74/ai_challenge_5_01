"""–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG (Retrieval-Augmented Generation)"""
import logging
from typing import List, Dict, Any, Optional, Tuple

from document_indexer import load_index, search_index
from openai_client import query_openai

logger = logging.getLogger(__name__)

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
DEFAULT_TOP_K = 5

# –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ)
# –ó–Ω–∞—á–µ–Ω–∏—è –æ—Ç -1 –¥–æ 1, –≥–¥–µ 1 - –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, 0 - –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, -1 - –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ—Å—Ç—å
DEFAULT_RELEVANCE_THRESHOLD = 0.0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ —Ñ–∏–ª—å—Ç—Ä—É–µ–º (–ø—Ä–∏–Ω–∏–º–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)


def filter_by_relevance_threshold(
    results: List[Dict[str, Any]], 
    threshold: float = DEFAULT_RELEVANCE_THRESHOLD
) -> List[Dict[str, Any]]:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å similarity
        threshold: –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –æ—Ç -1 –¥–æ 1)
    
    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –≥–¥–µ similarity >= threshold
    """
    if threshold is None or threshold <= -1.0:
        # –ï—Å–ª–∏ –ø–æ—Ä–æ–≥ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return results
    
    filtered = [r for r in results if r.get('similarity', -1.0) >= threshold]
    
    logger.info(
        f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É {threshold:.3f}: "
        f"–æ—Å—Ç–∞–ª–æ—Å—å {len(filtered)} –∏–∑ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
    )
    
    return filtered


def rerank_results(
    results: List[Dict[str, Any]], 
    query: str,
    method: str = "similarity"
) -> List[Dict[str, Any]]:
    """–†–µ—Ä–∞–Ω–∫–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        method: –ú–µ—Ç–æ–¥ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞:
            - "similarity": —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ similarity (—É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ)
            - "diversity": —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—É–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã)
            - "hybrid": –∫–æ–º–±–∏–Ω–∞—Ü–∏—è similarity –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
    
    Returns:
        –†–µ—Ä–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    if not results:
        return results
    
    if method == "similarity":
        # –£–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ similarity, –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–Ω–≥–∏
        for rank, result in enumerate(results, 1):
            result['rank'] = rank
        return results
    
    elif method == "diversity":
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É —á–∞–Ω–∫–∞
        seen_texts = set()
        diverse_results = []
        
        for result in results:
            chunk = result.get('chunk', {})
            text = chunk.get('text', '').strip()
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É)
            text_normalized = ' '.join(text.lower().split())
            
            if text_normalized not in seen_texts and len(text_normalized) > 0:
                seen_texts.add(text_normalized)
                diverse_results.append(result)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–Ω–≥–∏
        for rank, result in enumerate(diverse_results, 1):
            result['rank'] = rank
        
        logger.info(
            f"–†–µ—Ä–∞–Ω–∫–∏–Ω–≥ –ø–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—é: –æ—Å—Ç–∞–ª–æ—Å—å {len(diverse_results)} –∏–∑ {len(results)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
        )
        
        return diverse_results
    
    elif method == "hybrid":
        # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø–æ similarity, –ø–æ—Ç–æ–º —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        diverse_results = rerank_results(results, query, method="diversity")
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ similarity —Å—Ä–µ–¥–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö
        diverse_results.sort(key=lambda x: x.get('similarity', 0.0), reverse=True)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–Ω–≥–∏
        for rank, result in enumerate(diverse_results, 1):
            result['rank'] = rank
        
        return diverse_results
    
    else:
        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞: {method}, –∏—Å–ø–æ–ª—å–∑—É–µ–º similarity")
        return rerank_results(results, query, method="similarity")


def format_sources_for_display(sources: List[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    
    Args:
        sources: –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –∫–ª—é—á–∞–º–∏ source_file, similarity, text
        
    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ markdown
    """
    if not sources:
        return ""
    
    source_parts = []
    source_parts.append("üìö **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**\n")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ —Ñ–∞–π–ª–∞–º
    sources_by_file = {}
    for i, source in enumerate(sources, 1):
        file_name = source.get('source_file', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
        if file_name not in sources_by_file:
            sources_by_file[file_name] = []
        sources_by_file[file_name].append({
            'index': i,
            'similarity': source.get('similarity', 0.0),
            'text': source.get('text', '')
        })
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
    for file_name, file_sources in sources_by_file.items():
        source_parts.append(f"üìÑ **{file_name}**")
        for source_info in file_sources:
            similarity = source_info['similarity']
            source_parts.append(f"  ‚Ä¢ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.3f}")
    
    return "\n".join(source_parts)


def format_chunks_for_context(chunks: List[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç LLM
    
    Args:
        chunks: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å —á–∞–Ω–∫–∞–º–∏
        
    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ —á–∞–Ω–∫–æ–≤
    """
    if not chunks:
        return ""
    
    context_parts = []
    for i, result in enumerate(chunks, 1):
        chunk = result.get('chunk', {})
        similarity = result.get('similarity', 0.0)
        text = chunk.get('text', '')
        source = chunk.get('source_file', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
        
        if text:
            context_parts.append(
                f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.3f}) –∏–∑ {source}]:\n{text}"
            )
    
    return "\n\n".join(context_parts)


def build_rag_prompt(question: str, context: str) -> str:
    """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ RAG
    
    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        
    Returns:
        –ü—Ä–æ–º–ø—Ç —Å –≤–æ–ø—Ä–æ—Å–æ–º –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    """
    if context:
        prompt = (
            f"–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å:\n\n"
            f"{context}\n\n"
            f"–í–æ–ø—Ä–æ—Å: {question}\n\n"
            f"–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. "
            f"–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —É–∫–∞–∂–∏ —ç—Ç–æ. "
            f"–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–∞, —É–∫–∞–∂–∏ —ç—Ç–æ."
        )
    else:
        prompt = question
    
    return prompt


async def query_with_rag(
    question: str,
    conversation_history: list,
    system_prompt: str,
    temperature: float,
    model: str,
    max_tokens: int,
    bot=None,
    tools: Optional[List[Dict[str, Any]]] = None,
    top_k: int = DEFAULT_TOP_K,
    index_path: Optional[str] = None,
    relevance_threshold: Optional[float] = None,
    rerank_method: Optional[str] = None,
    use_filter: bool = True
) -> Tuple[str, list, List[Dict[str, Any]]]:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG
    
    –ü—Ä–æ—Ü–µ—Å—Å:
    1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    2. –ò—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –ø–æ –≤–æ–ø—Ä–æ—Å—É
    3. –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    4. –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –º–µ—Ç–æ–¥)
    5. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ —Å –≤–æ–ø—Ä–æ—Å–æ–º
    6. –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM
    
    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        model: –ú–æ–¥–µ–ª—å LLM
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
        bot: –≠–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        tools: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        index_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–Ω–¥–µ–∫—Å–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π)
        relevance_threshold: –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (None = –Ω–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å)
        rerank_method: –ú–µ—Ç–æ–¥ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞ ("similarity", "diversity", "hybrid" –∏–ª–∏ None)
        use_filter: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –ø–æ—Ä–æ–≥—É
    
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–≤–µ—Ç, –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è, –∏—Å—Ç–æ—á–Ω–∏–∫–∏)
        –ò—Å—Ç–æ—á–Ω–∏–∫–∏ - —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏: source_file, similarity, text
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å
    index = load_index(index_path)
    
    if not index:
        logger.warning("–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ RAG")
        answer, history = await query_openai(
            question,
            conversation_history,
            system_prompt,
            temperature,
            model,
            max_tokens,
            bot,
            tools
        )
        return answer, history, []
    
    # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
    logger.info(f"–ò—â—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {question[:100]}...")
    try:
        # –ü–æ–ª—É—á–∞–µ–º –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
        search_results = search_index(question, index, top_k=top_k * 2)  # –ë–µ—Ä–µ–º –≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ RAG")
        search_results = []
    
    if not search_results:
        logger.info("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ OLLama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ RAG")
        answer, history = await query_openai(
            question,
            conversation_history,
            system_prompt,
            temperature,
            model,
            max_tokens,
            bot,
            tools
        )
        return answer, history, []
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
    if use_filter and relevance_threshold is not None:
        search_results = filter_by_relevance_threshold(search_results, relevance_threshold)
        logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –º–µ—Ç–æ–¥
    if rerank_method:
        search_results = rerank_results(search_results, question, method=rerank_method)
        logger.info(f"–ü–æ—Å–ª–µ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞ ({rerank_method}): {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ top_k –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
    search_results = search_results[:top_k]
    
    if not search_results:
        logger.info("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ RAG")
        answer, history = await query_openai(
            question,
            conversation_history,
            system_prompt,
            temperature,
            model,
            max_tokens,
            bot,
            tools
        )
        return answer, history, []
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —á–∞–Ω–∫–æ–≤
    context = format_chunks_for_context(search_results)
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    rag_prompt = build_rag_prompt(question, context)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
    answer, history = await query_openai(
        rag_prompt,
        conversation_history,
        system_prompt,
        temperature,
        model,
        max_tokens,
        bot,
        tools
    )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ search_results
    sources = []
    for result in search_results:
        chunk = result.get('chunk', {})
        source_info = {
            'source_file': chunk.get('source_file', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫'),
            'similarity': result.get('similarity', 0.0),
            'text': chunk.get('text', '')[:200] + '...' if len(chunk.get('text', '')) > 200 else chunk.get('text', '')
        }
        sources.append(source_info)
    
    return answer, history, sources


async def compare_rag_with_and_without_filter(
    question: str,
    conversation_history: list,
    system_prompt: str,
    temperature: float,
    model: str,
    max_tokens: int,
    bot=None,
    tools: Optional[List[Dict[str, Any]]] = None,
    top_k: int = DEFAULT_TOP_K,
    index_path: Optional[str] = None,
    relevance_threshold: float = 0.3,
    rerank_method: Optional[str] = None
) -> Dict[str, Any]:
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
    
    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        model: –ú–æ–¥–µ–ª—å LLM
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
        bot: –≠–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        tools: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        index_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–Ω–¥–µ–∫—Å–∞
        relevance_threshold: –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        rerank_method: –ú–µ—Ç–æ–¥ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
        - answer_without_filter: –æ—Ç–≤–µ—Ç –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        - answer_with_filter: –æ—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        - chunks_without_filter: —á–∞–Ω–∫–∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        - chunks_with_filter: —á–∞–Ω–∫–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        - comparison: –∞–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    logger.info("–ù–∞—á–∏–Ω–∞—é —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
    logger.info("–ü–æ–ª—É—á–∞—é –æ—Ç–≤–µ—Ç –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏...")
    answer_without_filter, history_without_filter, _ = await query_with_rag(
        question,
        conversation_history,
        system_prompt,
        temperature,
        model,
        max_tokens,
        bot,
        tools,
        top_k,
        index_path,
        relevance_threshold=None,
        rerank_method=None,
        use_filter=False
    )
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–æ–º
    logger.info(f"–ü–æ–ª—É—á–∞—é –æ—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π (–ø–æ—Ä–æ–≥: {relevance_threshold})...")
    answer_with_filter, history_with_filter, _ = await query_with_rag(
        question,
        conversation_history,
        system_prompt,
        temperature,
        model,
        max_tokens,
        bot,
        tools,
        top_k,
        index_path,
        relevance_threshold=relevance_threshold,
        rerank_method=rerank_method,
        use_filter=True
    )
    
    # –ü–æ–ª—É—á–∞–µ–º —á–∞–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    chunks_without_filter = []
    chunks_with_filter = []
    index = load_index(index_path)
    if index:
        try:
            search_results_no_filter = search_index(question, index, top_k=top_k * 2)
            chunks_without_filter = search_results_no_filter[:top_k]
            
            if relevance_threshold is not None:
                search_results_filtered = filter_by_relevance_threshold(
                    search_results_no_filter, 
                    relevance_threshold
                )
                if rerank_method:
                    search_results_filtered = rerank_results(
                        search_results_filtered, 
                        question, 
                        method=rerank_method
                    )
                chunks_with_filter = search_results_filtered[:top_k]
            else:
                chunks_with_filter = chunks_without_filter
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —á–∞–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    comparison = analyze_filter_comparison(
        question,
        answer_without_filter,
        answer_with_filter,
        chunks_without_filter,
        chunks_with_filter,
        relevance_threshold
    )
    
    return {
        "answer_without_filter": answer_without_filter,
        "answer_with_filter": answer_with_filter,
        "chunks_without_filter": chunks_without_filter,
        "chunks_with_filter": chunks_with_filter,
        "comparison": comparison
    }


async def compare_rag_vs_no_rag(
    question: str,
    conversation_history: list,
    system_prompt: str,
    temperature: float,
    model: str,
    max_tokens: int,
    bot=None,
    tools: Optional[List[Dict[str, Any]]] = None,
    top_k: int = DEFAULT_TOP_K,
    index_path: Optional[str] = None
) -> Dict[str, Any]:
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ —Å RAG –∏ –±–µ–∑ RAG
    
    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        model: –ú–æ–¥–µ–ª—å LLM
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
        bot: –≠–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        tools: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        index_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–Ω–¥–µ–∫—Å–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
        - answer_with_rag: –æ—Ç–≤–µ—Ç —Å RAG
        - answer_without_rag: –æ—Ç–≤–µ—Ç –±–µ–∑ RAG
        - rag_context: –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG
        - comparison: –∞–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    logger.info("–ù–∞—á–∏–Ω–∞—é —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ —Å RAG –∏ –±–µ–∑ RAG")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –±–µ–∑ RAG
    logger.info("–ü–æ–ª—É—á–∞—é –æ—Ç–≤–µ—Ç –±–µ–∑ RAG...")
    answer_without_rag, history_without_rag = await query_openai(
        question,
        conversation_history,
        system_prompt,
        temperature,
        model,
        max_tokens,
        bot,
        tools
    )
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å RAG
    logger.info("–ü–æ–ª—É—á–∞—é –æ—Ç–≤–µ—Ç —Å RAG...")
    answer_with_rag, history_with_rag, _ = await query_with_rag(
        question,
        conversation_history,
        system_prompt,
        temperature,
        model,
        max_tokens,
        bot,
        tools,
        top_k,
        index_path
    )
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç RAG –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    rag_context = ""
    index = load_index(index_path)
    if index:
        search_results = search_index(question, index, top_k=top_k)
        if search_results:
            rag_context = format_chunks_for_context(search_results)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    comparison = analyze_comparison(
        question,
        answer_without_rag,
        answer_with_rag,
        rag_context
    )
    
    return {
        "answer_with_rag": answer_with_rag,
        "answer_without_rag": answer_without_rag,
        "rag_context": rag_context,
        "comparison": comparison
    }


def analyze_filter_comparison(
    question: str,
    answer_without_filter: str,
    answer_with_filter: str,
    chunks_without_filter: List[Dict[str, Any]],
    chunks_with_filter: List[Dict[str, Any]],
    threshold: float
) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
    
    Args:
        question: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        answer_without_filter: –û—Ç–≤–µ—Ç –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        answer_with_filter: –û—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        chunks_without_filter: –ß–∞–Ω–∫–∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        chunks_with_filter: –ß–∞–Ω–∫–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        threshold: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    
    Returns:
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    analysis_parts = []
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    len_without = len(answer_without_filter)
    len_with = len(answer_with_filter)
    word_count_without = len(answer_without_filter.split())
    word_count_with = len(answer_with_filter.split())
    
    chunks_count_without = len(chunks_without_filter)
    chunks_count_with = len(chunks_with_filter)
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —á–∞–Ω–∫–æ–≤
    avg_similarity_without = 0.0
    if chunks_without_filter:
        similarities = [r.get('similarity', 0.0) for r in chunks_without_filter]
        avg_similarity_without = sum(similarities) / len(similarities) if similarities else 0.0
    
    avg_similarity_with = 0.0
    if chunks_with_filter:
        similarities = [r.get('similarity', 0.0) for r in chunks_with_filter]
        avg_similarity_with = sum(similarities) / len(similarities) if similarities else 0.0
    
    analysis_parts.append("=== –ê–ù–ê–õ–ò–ó –°–†–ê–í–ù–ï–ù–ò–Ø –° –§–ò–õ–¨–¢–†–û–ú –ò –ë–ï–ó ===")
    analysis_parts.append(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤:")
    analysis_parts.append(f"  ‚Ä¢ –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞: {len_without} —Å–∏–º–≤–æ–ª–æ–≤, {word_count_without} —Å–ª–æ–≤")
    analysis_parts.append(f"  ‚Ä¢ –° —Ñ–∏–ª—å—Ç—Ä–æ–º (–ø–æ—Ä–æ–≥ {threshold:.3f}): {len_with} —Å–∏–º–≤–æ–ª–æ–≤, {word_count_with} —Å–ª–æ–≤")
    analysis_parts.append(f"  ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {len_with - len_without:+d} —Å–∏–º–≤–æ–ª–æ–≤ ({word_count_with - word_count_without:+d} —Å–ª–æ–≤)\n")
    
    analysis_parts.append(f"üìö –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤:")
    analysis_parts.append(f"  ‚Ä¢ –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞: {chunks_count_without} —á–∞–Ω–∫–æ–≤, —Å—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_similarity_without:.3f}")
    analysis_parts.append(f"  ‚Ä¢ –° —Ñ–∏–ª—å—Ç—Ä–æ–º: {chunks_count_with} —á–∞–Ω–∫–æ–≤, —Å—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_similarity_with:.3f}")
    if chunks_count_without > 0:
        filtered_out = chunks_count_without - chunks_count_with
        filter_rate = (filtered_out / chunks_count_without) * 100
        analysis_parts.append(f"  ‚Ä¢ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {filtered_out} —á–∞–Ω–∫–æ–≤ ({filter_rate:.1f}%)\n")
    
    # –í—ã–≤–æ–¥—ã
    analysis_parts.append("=== –í–´–í–û–î–´ ===")
    
    if chunks_count_with == 0:
        analysis_parts.append("‚ùå –§–∏–ª—å—Ç—Ä —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–π: –≤—Å–µ —á–∞–Ω–∫–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã")
        analysis_parts.append(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —É–º–µ–Ω—å—à–∏—Ç–µ –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (—Ç–µ–∫—É—â–∏–π: {threshold:.3f})")
    elif chunks_count_with < chunks_count_without * 0.5:
        analysis_parts.append("‚ö†Ô∏è –§–∏–ª—å—Ç—Ä –æ—á–µ–Ω—å —Å—Ç—Ä–æ–≥–∏–π: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –±–æ–ª–µ–µ 50% —á–∞–Ω–∫–æ–≤")
        analysis_parts.append(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –¥–æ {threshold * 0.7:.3f}")
    elif chunks_count_with == chunks_count_without:
        analysis_parts.append("‚û°Ô∏è –§–∏–ª—å—Ç—Ä –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞")
        analysis_parts.append(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —É–≤–µ–ª–∏—á—å—Ç–µ –ø–æ—Ä–æ–≥ –¥–æ {threshold * 1.5:.3f} –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    else:
        analysis_parts.append(f"‚úÖ –§–∏–ª—å—Ç—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {chunks_count_without - chunks_count_with} –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤
    if avg_similarity_with > avg_similarity_without:
        analysis_parts.append(f"‚úÖ –§–∏–ª—å—Ç—Ä —É–ª—É—á—à–∏–ª –∫–∞—á–µ—Å—Ç–≤–æ: —Å—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —á–∞–Ω–∫–æ–≤ –≤—ã—Ä–æ—Å–ª–∞ —Å {avg_similarity_without:.3f} –¥–æ {avg_similarity_with:.3f}")
    elif avg_similarity_with < avg_similarity_without:
        analysis_parts.append(f"‚ö†Ô∏è –§–∏–ª—å—Ç—Ä —Å–Ω–∏–∑–∏–ª —Å—Ä–µ–¥–Ω—é—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: —Å {avg_similarity_without:.3f} –¥–æ {avg_similarity_with:.3f}")
        analysis_parts.append("üí° –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∏–ª—å—Ç—Ä —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–π –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª –ø–æ–ª–µ–∑–Ω—ã–µ —á–∞–Ω–∫–∏")
    else:
        analysis_parts.append("‚û°Ô∏è –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —á–∞–Ω–∫–æ–≤ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–æ–≤
    len_ratio = len_with / len_without if len_without > 0 else 1.0
    if len_ratio > 1.1:
        analysis_parts.append("‚úÖ –û—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π (–Ω–∞ 10%+ –¥–ª–∏–Ω–Ω–µ–µ)")
    elif len_ratio < 0.9:
        analysis_parts.append("‚ö†Ô∏è –û—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –∫–æ—Ä–æ—á–µ (–Ω–∞ 10%+), –≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ—Ç–µ—Ä—è–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    else:
        analysis_parts.append("‚û°Ô∏è –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞")
    
    return "\n".join(analysis_parts)


def analyze_comparison(
    question: str,
    answer_without_rag: str,
    answer_with_rag: str,
    rag_context: str
) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –∏ –¥–µ–ª–∞–µ—Ç –≤—ã–≤–æ–¥—ã
    
    Args:
        question: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        answer_without_rag: –û—Ç–≤–µ—Ç –±–µ–∑ RAG
        answer_with_rag: –û—Ç–≤–µ—Ç —Å RAG
        rag_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG
    
    Returns:
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    analysis_parts = []
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    len_without = len(answer_without_rag)
    len_with = len(answer_with_rag)
    word_count_without = len(answer_without_rag.split())
    word_count_with = len(answer_with_rag.split())
    
    analysis_parts.append("=== –ê–ù–ê–õ–ò–ó –°–†–ê–í–ù–ï–ù–ò–Ø ===")
    analysis_parts.append(f"\nüìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–æ–≤:")
    analysis_parts.append(f"  ‚Ä¢ –ë–µ–∑ RAG: {len_without} —Å–∏–º–≤–æ–ª–æ–≤, {word_count_without} —Å–ª–æ–≤")
    analysis_parts.append(f"  ‚Ä¢ –° RAG: {len_with} —Å–∏–º–≤–æ–ª–æ–≤, {word_count_with} —Å–ª–æ–≤")
    analysis_parts.append(f"  ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {len_with - len_without:+d} —Å–∏–º–≤–æ–ª–æ–≤ ({word_count_with - word_count_without:+d} —Å–ª–æ–≤)\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    if rag_context:
        analysis_parts.append("‚úÖ RAG –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        analysis_parts.append(f"üìÑ –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(rag_context)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –æ—Ç–≤–µ—Ç–µ
        context_keywords = set(rag_context.lower().split()[:30])  # –ü–µ—Ä–≤—ã–µ 30 —Å–ª–æ–≤
        answer_keywords = set(answer_with_rag.lower().split())
        overlap = len(context_keywords & answer_keywords)
        
        if overlap > 0:
            analysis_parts.append(f"‚úÖ –í –æ—Ç–≤–µ—Ç–µ —Å RAG –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ª–æ–≤–∞ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ({overlap} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π)")
        else:
            analysis_parts.append("‚ö†Ô∏è –í –æ—Ç–≤–µ—Ç–µ —Å RAG –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ —è–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_terms = [w for w in rag_context.lower().split() if len(w) > 5]
        answer_terms = answer_with_rag.lower()
        specific_terms_used = sum(1 for term in context_terms[:10] if term in answer_terms)
        if specific_terms_used > 0:
            analysis_parts.append(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ({specific_terms_used} —Ç–µ—Ä–º–∏–Ω–æ–≤)")
    else:
        analysis_parts.append("‚ùå RAG –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç (–∏–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤)")
    
    # –í—ã–≤–æ–¥—ã
    analysis_parts.append("\n=== –í–´–í–û–î–´ ===")
    
    if not rag_context:
        analysis_parts.append("‚ùå RAG –Ω–µ –ø–æ–º–æ–≥: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º")
        analysis_parts.append("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (document_index/index.json)")
    else:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤
        len_ratio = len_with / len_without if len_without > 0 else 1.0
        
        if len_ratio > 1.3:
            analysis_parts.append("‚úÖ RAG –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç —Å RAG –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π (–Ω–∞ 30%+ –¥–ª–∏–Ω–Ω–µ–µ)")
        elif len_ratio > 1.1:
            analysis_parts.append("‚úÖ RAG –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç —Å RAG –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π (–Ω–∞ 10-30% –¥–ª–∏–Ω–Ω–µ–µ)")
        elif len_ratio < 0.7:
            analysis_parts.append("‚ö†Ô∏è RAG –Ω–µ –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç —Å RAG –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—á–µ (–Ω–∞ 30%+), –≤–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –æ–≥—Ä–∞–Ω–∏—á–∏–ª–∞—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º")
        elif len_ratio < 0.9:
            analysis_parts.append("‚ö†Ô∏è RAG –Ω–µ –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç —Å RAG –∫–æ—Ä–æ—á–µ (–Ω–∞ 10-30%), –≤–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –æ–≥—Ä–∞–Ω–∏—á–∏–ª–∞—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º")
        else:
            analysis_parts.append("‚û°Ô∏è RAG –æ–∫–∞–∑–∞–ª —É–º–µ—Ä–µ–Ω–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ: –æ—Ç–≤–µ—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã –ø–æ –¥–ª–∏–Ω–µ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        question_keywords = set(question.lower().split())
        answer_without_keywords = set(answer_without_rag.lower().split())
        answer_with_keywords = set(answer_with_rag.lower().split())
        
        relevance_without = len(question_keywords & answer_without_keywords)
        relevance_with = len(question_keywords & answer_with_keywords)
        
        if relevance_with > relevance_without:
            analysis_parts.append(f"‚úÖ RAG –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω –≤–æ–ø—Ä–æ—Å—É (–±–æ–ª—å—à–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {relevance_with} vs {relevance_without})")
        elif relevance_with == relevance_without and relevance_with > 0:
            analysis_parts.append(f"‚û°Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞: {relevance_with} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –æ–±–æ–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π
        if "–∏—Å—Ç–æ—á–Ω–∏–∫" in answer_with_rag.lower() or "–¥–æ–∫—É–º–µ–Ω—Ç" in answer_with_rag.lower():
            analysis_parts.append("‚úÖ RAG –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ —Å RAG –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ –±–µ–∑ RAG
        answer_without_words = set(answer_without_rag.lower().split())
        answer_with_words = set(answer_with_rag.lower().split())
        unique_words = answer_with_words - answer_without_words
        if len(unique_words) > 10:
            analysis_parts.append(f"‚úÖ RAG –ø–æ–º–æ–≥: –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ({len(unique_words)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤)")
    
    return "\n".join(analysis_parts)

