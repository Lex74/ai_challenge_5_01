#!/usr/bin/env python3
"""
CLI –∞–≥–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ OLLama
–ü–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—â–∞—Ç—å—Å—è —Å –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É
"""

import os
import sys
import json
import requests
import argparse
from typing import List, Optional, Dict, Any

# URL OLLama API
OLLAMA_API_URL = os.getenv('OLLAMA_API_URL', 'http://localhost:11434')
OLLAMA_API_BASE = f"{OLLAMA_API_URL}/api"

# –¶–≤–µ—Ç–∞ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    END = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


def print_colored(text: str, color: str = Colors.END, end: str = '\n', flush: bool = False):
    """–ü–µ—á–∞—Ç–∞–µ—Ç —Ü–≤–µ—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç"""
    print(f"{color}{text}{Colors.END}", end=end, flush=flush)


def get_available_models() -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/tags", timeout=5)
        response.raise_for_status()
        data = response.json()
        return [model['name'] for model in data.get('models', [])]
    except Exception as e:
        print_colored(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}", Colors.RED)
        return []


def check_ollama_available() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OLLama —Å–µ—Ä–≤–µ—Ä–∞"""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/tags", timeout=5)
        return response.status_code == 200
    except:
        return False


def generate_response(model: str, prompt: str, stream: bool = True) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"""
    url = f"{OLLAMA_API_BASE}/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": stream
    }
    
    try:
        response = requests.post(url, json=payload, stream=stream, timeout=300)
        response.raise_for_status()
        
        if stream:
            full_response = ""
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line)
                        if 'response' in data:
                            chunk = data['response']
                            print(chunk, end='', flush=True)
                            full_response += chunk
                        if data.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
            print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞
            return full_response
        else:
            data = response.json()
            return data.get('response', '')
    except requests.exceptions.RequestException as e:
        print_colored(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏: {e}", Colors.RED)
        return ""


def chat_with_model(model: str, messages: List[Dict[str, str]], stream: bool = True) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ chat API"""
    url = f"{OLLAMA_API_BASE}/chat"
    payload = {
        "model": model,
        "messages": messages,
        "stream": stream
    }
    
    try:
        response = requests.post(url, json=payload, stream=stream, timeout=300)
        response.raise_for_status()
        
        if stream:
            full_response = ""
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line)
                        if 'message' in data and 'content' in data['message']:
                            chunk = data['message']['content']
                            print(chunk, end='', flush=True)
                            full_response += chunk
                        if data.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
            print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞
            return full_response
        else:
            data = response.json()
            return data.get('message', {}).get('content', '')
    except requests.exceptions.RequestException as e:
        print_colored(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏: {e}", Colors.RED)
        return ""


def show_models():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    models = get_available_models()
    if not models:
        print_colored("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–ª–∏ OLLama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", Colors.RED)
        return
    
    print_colored("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:", Colors.BOLD)
    for i, model in enumerate(models, 1):
        print_colored(f"  {i}. {model}", Colors.CYAN)
    print()


def interactive_mode(model: str):
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –æ–±—â–µ–Ω–∏—è —Å –º–æ–¥–µ–ª—å—é"""
    if not check_ollama_available():
        print_colored("‚ùå OLLama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–ø—É—â–µ–Ω.", Colors.RED)
        print_colored("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve", Colors.YELLOW)
        return
    
    models = get_available_models()
    if not models:
        print_colored("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", Colors.RED)
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if model not in models:
        print_colored(f"‚ùå –ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", Colors.RED)
        print_colored("–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:", Colors.YELLOW)
        for m in models:
            print_colored(f"  - {m}", Colors.CYAN)
        return
    
    print_colored(f"\nü§ñ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Å –º–æ–¥–µ–ª—å—é: {model}", Colors.BOLD)
    print_colored("–ö–æ–º–∞–Ω–¥—ã:", Colors.YELLOW)
    print_colored("  /help - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É", Colors.CYAN)
    print_colored("  /models - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π", Colors.CYAN)
    print_colored("  /switch <model> - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å", Colors.CYAN)
    print_colored("  /clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞", Colors.CYAN)
    print_colored("  /exit –∏–ª–∏ /quit - –≤—ã–π—Ç–∏", Colors.CYAN)
    print_colored("  /history - –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞", Colors.CYAN)
    print()
    
    conversation_history = []
    
    while True:
        try:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç
            print_colored(f"[{model}]", Colors.GREEN, end=" ")
            user_input = input().strip()
            
            if not user_input:
                continue
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
            if user_input.startswith('/'):
                command = user_input.split()[0]
                
                if command in ['/exit', '/quit', '/q']:
                    print_colored("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!", Colors.YELLOW)
                    break
                
                elif command == '/help':
                    print_colored("\nüìñ –°–ø—Ä–∞–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º:", Colors.BOLD)
                    print_colored("  /help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É", Colors.CYAN)
                    print_colored("  /models - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", Colors.CYAN)
                    print_colored("  /switch <model> - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å", Colors.CYAN)
                    print_colored("  /clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞", Colors.CYAN)
                    print_colored("  /history - –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞", Colors.CYAN)
                    print_colored("  /exit, /quit, /q - –≤—ã–π—Ç–∏ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã", Colors.CYAN)
                    print()
                
                elif command == '/models':
                    show_models()
                
                elif command == '/switch':
                    parts = user_input.split()
                    if len(parts) < 2:
                        print_colored("‚ùå –£–∫–∞–∂–∏—Ç–µ –º–æ–¥–µ–ª—å: /switch <model_name>", Colors.RED)
                        continue
                    new_model = parts[1]
                    if new_model in models:
                        model = new_model
                        conversation_history = []  # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ —Å–º–µ–Ω–µ –º–æ–¥–µ–ª–∏
                        print_colored(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –º–æ–¥–µ–ª—å: {model}", Colors.GREEN)
                    else:
                        print_colored(f"‚ùå –ú–æ–¥–µ–ª—å '{new_model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", Colors.RED)
                        show_models()
                
                elif command == '/clear':
                    conversation_history = []
                    print_colored("‚úÖ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞", Colors.GREEN)
                
                elif command == '/history':
                    if not conversation_history:
                        print_colored("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø—É—Å—Ç–∞", Colors.YELLOW)
                    else:
                        print_colored("\nüìú –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:", Colors.BOLD)
                        for i, msg in enumerate(conversation_history, 1):
                            role = msg['role']
                            content = msg['content'][:100] + "..." if len(msg['content']) > 100 else msg['content']
                            color = Colors.CYAN if role == 'user' else Colors.GREEN
                            print_colored(f"  {i}. [{role}]: {content}", color)
                        print()
                
                else:
                    print_colored(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {command}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help", Colors.RED)
                
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
            conversation_history.append({
                "role": "user",
                "content": user_input
            })
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
            print_colored(f"[{model}]", Colors.BLUE, end=" ")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = chat_with_model(model, conversation_history, stream=True)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é
            if response:
                conversation_history.append({
                    "role": "assistant",
                    "content": response
                })
            
            print()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞
            
        except KeyboardInterrupt:
            print_colored("\n\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!", Colors.YELLOW)
            break
        except EOFError:
            print_colored("\n\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!", Colors.YELLOW)
            break
        except Exception as e:
            print_colored(f"\n‚ùå –û—à–∏–±–∫–∞: {e}", Colors.RED)


def single_query(model: str, prompt: str):
    """–û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏"""
    if not check_ollama_available():
        print_colored("‚ùå OLLama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–ø—É—â–µ–Ω.", Colors.RED)
        print_colored("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve", Colors.YELLOW)
        return
    
    models = get_available_models()
    if not models:
        print_colored("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", Colors.RED)
        return
    
    if model not in models:
        print_colored(f"‚ùå –ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", Colors.RED)
        print_colored("–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:", Colors.YELLOW)
        for m in models:
            print_colored(f"  - {m}", Colors.CYAN)
        return
    
    print_colored(f"ü§ñ –ú–æ–¥–µ–ª—å: {model}", Colors.BOLD)
    print_colored(f"üí¨ –ó–∞–ø—Ä–æ—Å: {prompt}\n", Colors.CYAN)
    print_colored("üìù –û—Ç–≤–µ—Ç:", Colors.BOLD)
    
    messages = [{"role": "user", "content": prompt}]
    chat_with_model(model, messages, stream=True)
    print()


def main():
    parser = argparse.ArgumentParser(
        description='CLI –∞–≥–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ OLLama',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Å –º–æ–¥–µ–ª—å—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
  python ollama_cli.py
  
  # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª—å—é
  python ollama_cli.py -m qwen2.5:7b
  
  # –û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
  python ollama_cli.py -m qwen2.5:7b -p "–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ"
  
  # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
  python ollama_cli.py --list-models
        """
    )
    
    parser.add_argument(
        '-m', '--model',
        type=str,
        help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: qwen2.5:7b)'
    )
    
    parser.add_argument(
        '-p', '--prompt',
        type=str,
        help='–û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ (–Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º)'
    )
    
    parser.add_argument(
        '--list-models',
        action='store_true',
        help='–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –≤—ã–π—Ç–∏'
    )
    
    parser.add_argument(
        '--api-url',
        type=str,
        default=None,
        help=f'URL OLLama API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {OLLAMA_API_URL})'
    )
    
    args = parser.parse_args()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º URL API, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    global OLLAMA_API_BASE
    if args.api_url:
        OLLAMA_API_BASE = f"{args.api_url}/api"
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏ –≤—ã—Ö–æ–¥–∏–º
    if args.list_models:
        show_models()
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OLLama
    if not check_ollama_available():
        print_colored("‚ùå OLLama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", Colors.RED)
        print_colored("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ OLLama –∑–∞–ø—É—â–µ–Ω: ollama serve", Colors.YELLOW)
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    default_model = args.model or 'qwen2.5:7b'
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—Ä–æ–º–ø—Ç, –¥–µ–ª–∞–µ–º –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    if args.prompt:
        single_query(default_model, args.prompt)
    else:
        # –ò–Ω–∞—á–µ –∑–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        interactive_mode(default_model)


if __name__ == '__main__':
    main()
