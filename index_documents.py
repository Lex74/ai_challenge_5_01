#!/usr/bin/env python3
"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OLLama"""
import os
import sys
import logging
import argparse
from pathlib import Path

from document_indexer import (
    index_documents,
    save_index,
    get_default_documents,
    INDEX_FILE
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    parser = argparse.ArgumentParser(
        description='–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OLLama'
    )
    parser.add_argument(
        'files',
        nargs='*',
        help='–ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ñ–∞–π–ª—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)'
    )
    parser.add_argument(
        '--source-name',
        type=str,
        default=None,
        help='–ò–º—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ—Ç—Å—è –∏–∑ –∏–º–µ–Ω–∏ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=INDEX_FILE,
        help=f'–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {INDEX_FILE})'
    )
    parser.add_argument(
        '--chunk-size',
        type=int,
        default=None,
        help='–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 100, –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ CHUNK_SIZE)'
    )
    parser.add_argument(
        '--chunk-overlap',
        type=int,
        default=None,
        help='–†–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 20, –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ CHUNK_OVERLAP)'
    )
    parser.add_argument(
        '--no-store-text',
        action='store_true',
        help='–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –±—É–¥—É—Ç –±–µ–∑ —Ç–µ–∫—Å—Ç–∞)'
    )
    parser.add_argument(
        '--use-openai',
        action='store_true',
        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenAI —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤–º–µ—Å—Ç–æ OLLama (—Ç—Ä–µ–±—É–µ—Ç OPENAI_API_KEY)'
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    if args.files:
        file_paths = args.files
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        existing_files = []
        for file_path in file_paths:
            if Path(file_path).exists():
                existing_files.append(file_path)
            else:
                logger.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}, –ø—Ä–æ–ø—É—Å–∫–∞—é...")
        
        if not existing_files:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            sys.exit(1)
        
        file_paths = existing_files
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        file_paths = get_default_documents()
        if not file_paths:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            sys.exit(1)
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ñ–∞–π–ª—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {file_paths}")
    
    logger.info(f"–ù–∞—á–∏–Ω–∞—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é {len(file_paths)} —Ñ–∞–π–ª–æ–≤...")
    logger.info(f"–§–∞–π–ª—ã: {', '.join(file_paths)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    use_openai = args.use_openai
    
    if use_openai:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OPENAI_API_KEY
        from config import OPENAI_API_KEY
        if not OPENAI_API_KEY:
            print("\n‚ùå OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            print("   –î–æ–±–∞–≤—å—Ç–µ OPENAI_API_KEY –≤ —Ñ–∞–π–ª .env")
            sys.exit(1)
        print(f"\n‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAI —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (text-embedding-3-small)")
    else:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OLLama
        try:
            from document_indexer import check_ollama_available
            logger.info("–ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OLLama...")
            if not check_ollama_available():
                print("\n‚ùå OLLama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
                print(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ: curl {os.getenv('OLLAMA_API_URL', 'http://localhost:11434')}/api/tags")
                print(f"   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª—å: ollama pull nomic-embed-text")
                print(f"\n   –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --use-openai –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ OpenAI")
                sys.exit(1)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ OLLama: {e}")
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ OLLama: {e}")
            print(f"   –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --use-openai –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ OpenAI")
            sys.exit(1)
    
    try:
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        logger.info("–ù–∞—á–∏–Ω–∞—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–∞ –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        chunk_size = args.chunk_size
        chunk_overlap = args.chunk_overlap
        if chunk_size:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {chunk_size} —Å–∏–º–≤–æ–ª–æ–≤")
        if chunk_overlap:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —á–∞–Ω–∫–æ–≤: {chunk_overlap} —Å–∏–º–≤–æ–ª–æ–≤")
        
        index = index_documents(
            file_paths, 
            source_name=args.source_name, 
            process_in_batches=True, 
            batch_size=20,
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            store_text=not args.no_store_text,
            use_openai=use_openai
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å
        save_index(index, file_path=args.output)
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        metadata = index.get('metadata', {})
        total_chunks = metadata.get('total_chunks', 0)
        source_files = metadata.get('source_files', [])
        
        print("\n" + "="*60)
        print("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("="*60)
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  ‚Ä¢ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(source_files)}")
        print(f"  ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
        print(f"  ‚Ä¢ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {metadata.get('embedding_model', 'N/A')}")
        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {metadata.get('embedding_dim', 'N/A')}")
        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {metadata.get('chunk_size', 'N/A')} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  ‚Ä¢ –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —á–∞–Ω–∫–æ–≤: {metadata.get('chunk_overlap', 'N/A')} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"\nüìÅ –§–∞–π–ª—ã:")
        for i, file_path in enumerate(source_files, 1):
            print(f"  {i}. {file_path}")
        print(f"\nüíæ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {args.output}")
        print("="*60 + "\n")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}", exc_info=True)
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}\n")
        sys.exit(1)


if __name__ == '__main__':
    main()

